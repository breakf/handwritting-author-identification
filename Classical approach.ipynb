{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: 'C:/Users/Anastasia/Pictures/autors_segments'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2e86b6eeda52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'C:/Users/Anastasia/Pictures/autors_segments'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mclust\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-2e86b6eeda52>\u001b[0m in \u001b[0;36mget_features\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mskip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mautor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0msegments_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0msegment_number\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegments_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Системе не удается найти указанный путь: 'C:/Users/Anastasia/Pictures/autors_segments'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.cluster import KMeans\n",
    "from math import ceil\n",
    "\n",
    "def get_features(path):\n",
    "    features = []\n",
    "    names = []\n",
    "    skip = 0\n",
    "    for autor in os.listdir(path):\n",
    "        segments_path = os.path.join(path, autor)\n",
    "        segment_number += len(segments_path)\n",
    "        for segment in os.listdir(segments_path):\n",
    "            segment_path = os.path.join(segments_path, segment)\n",
    "            image = cv2.imread(segment_path)\n",
    "            if np.sum(image) == 0:\n",
    "                skip += 1\n",
    "                continue\n",
    "            features.append(get_features(image))\n",
    "            names.append(segment_path)\n",
    "    return features, np.array(names)\n",
    "\n",
    "def get_clusters(most_100, names, kernel_size = 13):\n",
    "    start = most_100[0]\n",
    "    clusters = []\n",
    "    clusters_images = []\n",
    "    for i in most_100:\n",
    "        segments_name = np.ravel(names[np.argwhere(clust == i)])\n",
    "        line = cv2.imread(segments_name[0])\n",
    "        images = [line]\n",
    "        class_segments = [get_features(line)]\n",
    "        for seg_path in segments_name[1:]:\n",
    "            img = cv2.imread(seg_path)\n",
    "            class_segments.append(get_features(img))\n",
    "            line = np.hstack((line, img))\n",
    "            images.append(img)\n",
    "        clusters.append(class_segments)\n",
    "        clusters_images.append(images)\n",
    "    return clusters, clusters_images\n",
    "    \n",
    "def find_closest_feature_vector(features, images):\n",
    "    dists = np.zeros((len(features), len(features)))\n",
    "    for (i, j) in itertools.product(range(len(features)), range(len(features))):\n",
    "            dists[i, j] = euclidean(features[i], features[j])\n",
    "    min_ind = np.argmin(np.min(dists, axis=1))\n",
    "    return features[min_ind], images[min_ind]\n",
    " \n",
    "if __name__ == \"__main__\": \n",
    "    path ='C:/Users/Anastasia/Pictures/autors_segments'\n",
    "    features, names = get_features(path)\n",
    "    kmeans = KMeans(n_clusters=150, random_state=0).fit(features)\n",
    "    clust = kmeans.labels_\n",
    "    max_cluster_size = Counter(clust).most_common(1)[0][1]\n",
    "    most_100 = [cluster for (cluster, count) in Counter(clust).most_common(200)[10:110]]\n",
    "\n",
    "    clusters, clusters_images = get_clusters(most_100, names)\n",
    "\n",
    "    cluster_centres = []\n",
    "    for clust, images in zip(clusters, clusters_images):\n",
    "        feature, image = find_closest_feature_vector(clust, images)\n",
    "        cluster_centres.append(feature)\n",
    "         \n",
    "    cluster_centres = np.array(cluster_centres)\n",
    "    np.save('cluster_centres_kernel_13', cluster_centres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SegmentWords'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1e7c4135b752>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mSegmentWords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSegmentFeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0meuclidean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'SegmentWords'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import SegmentWords\n",
    "import SegmentFeatures\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def dist(vector, features):\n",
    "    distances = []\n",
    "    for feature in features:\n",
    "        distances.append(euclidean(vector, feature))\n",
    "    distances = np.array(distances)\n",
    "    return np.argmin(distances)\n",
    "    \n",
    "    \n",
    "def transform(str_numb):\n",
    "    l, r = str_numb.split(\"_\")\n",
    "    return float(l + \".\" + r)\n",
    "    \n",
    "def get_str2numb_numb2dict(vect):\n",
    "    str_to_ind_dict = {}\n",
    "    count = 0\n",
    "    for v in vect:\n",
    "        if v not in str_to_ind_dict.keys():\n",
    "            str_to_ind_dict[v] = count\n",
    "            count += 1\n",
    "    reverse_dict = {v:k for k, v in str_to_ind_dict.items()}\n",
    "    return str_to_ind_dict, reverse_dict\n",
    "\n",
    "def apply_dict(dict_keys, X):\n",
    "    res = []\n",
    "    for x in X:\n",
    "        res.append(dict_keys[x])\n",
    "    return res\n",
    "    \n",
    "def compute_features(train_path, save_name_x, save_name_y):\n",
    "    train_features = []\n",
    "    train_y = []\n",
    "    for variant in os.listdir(train_path):\n",
    "        v = variant[-1]\n",
    "        autors_path = os.path.join(train_path, variant)\n",
    "        autors = os.listdir(autors_path)\n",
    "        for autor in autors:\n",
    "            train_y.append(str(v) + \"_\" + str(autor))\n",
    "            words = os.listdir(os.path.join(autors_path, autor))\n",
    "            path = os.path.join(autors_path, autor)\n",
    "            autor_feature =  np.zeros((len(cluster_centres)))\n",
    "            for word in words:\n",
    "                word_path = os.path.join(path, word)\n",
    "                image = cv2.imread(word_path)\n",
    "                segments = SegmentWords.get_segments(image, kernel_size = 11)\n",
    "                for segment in segments:\n",
    "                    if np.sum(segment == 0) > 20  and (255 in segment):\n",
    "                        feature = SegmentFeatures.get_features(np.stack((segment,)*3, axis=-1))\n",
    "                        autor_feature[dist(feature, cluster_centres)] += 1\n",
    "            train_features.append(autor_feature / max(autor_feature))\n",
    "            \n",
    "    np.save(save_name_x, train_features)\n",
    "    np.save(save_name_y, train_y)\n",
    "    return train_features, train_y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.cluster import KMeans\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour(image):\n",
    "    img = image[:,:,0]\n",
    "    ret, thresh = cv2.threshold(img,127,255,0)\n",
    "    _, contours, hierarchy = cv2.findContours(thresh, 1, 2)\n",
    "    return contours[0]\n",
    "\n",
    "def horizontal_hist(image):\n",
    "    img = image[:,:,0]\n",
    "    return list(np.sum(img / 255, axis = 0))\n",
    "\n",
    "def vertical_hist(image):\n",
    "    img = image[:,:,0]\n",
    "    return list(np.sum(img / 255, axis = 1))\n",
    "\n",
    "def upper_profile(image):\n",
    "    img = image[:,:,0]\n",
    "    black = np.argwhere(img == 0)\n",
    "    ind = min(black[:,0])\n",
    "    return list(img[ind, :] / 255)\n",
    "    \n",
    "def lower_profile(image):\n",
    "    img = image[:,:,0]\n",
    "    black = np.argwhere(img == 0)\n",
    "    ind = max(black[:,0])\n",
    "    return list(img[ind, :] / 255)\n",
    "\n",
    "def orientation(image):\n",
    "    cnt = get_contour(image)\n",
    "    if len(cnt) < 5:\n",
    "        return 0\n",
    "    (x,y), (MA,ma), angle = cv2.fitEllipse(cnt)\n",
    "    return angle\n",
    "       \n",
    "def rectangularity(image):\n",
    "    cnt = get_contour(image)\n",
    "    area = cv2.contourArea(cnt)\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    rect_area = w * h\n",
    "    return float(area) / rect_area\n",
    "    \n",
    "def solidity(image):\n",
    "    cnt = get_contour(image)\n",
    "    area = cv2.contourArea(cnt)\n",
    "    hull = cv2.convexHull(cnt)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    if hull_area == 0:\n",
    "        hull_area = 1\n",
    "    return float(area) / hull_area\n",
    "    \n",
    "def eccentricity(image):\n",
    "    img = image[:,:,0]\n",
    "    ret, thresh = cv2.threshold(img, 127, 255, 0)\n",
    "    cnt = get_contour(image)\n",
    "    area = cv2.contourArea(cnt)\n",
    "    moments = cv2.moments(thresh, 1)\n",
    "    if area == 0:\n",
    "        area = 1\n",
    "    return (((moments['m02'] - moments['m02']) ** 2) + 4 * moments['m11']) / area\n",
    "\n",
    "def elongation(image):\n",
    "    img = image[:,:,0]\n",
    "    cnt = get_contour(image)\n",
    "    area = cv2.contourArea(cnt)\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    iteration_count = 1\n",
    "    erosion = cv2.erode(img, kernel, iterations = 1)\n",
    "    while 255 in erosion:\n",
    "        erosion = cv2.erode(erosion, kernel, iterations = 1)\n",
    "        iteration_count += 1\n",
    "    return area / (2 * iteration_count * iteration_count)\n",
    "    \n",
    "def perimeter(image):\n",
    "    cnt = get_contour(image)\n",
    "    perimeter = cv2.arcLength(cnt, True)\n",
    "    return perimeter\n",
    "\n",
    "def get_features(image):\n",
    "    feature = horizontal_hist(image)\n",
    "    feature += vertical_hist(image)\n",
    "    feature += upper_profile(image)\n",
    "    feature += lower_profile(image)\n",
    "    feature.append(orientation(image))\n",
    "    feature.append(rectangularity(image))\n",
    "    feature.append(solidity(image))\n",
    "    feature.append(eccentricity(image))\n",
    "    feature.append(elongation(image))\n",
    "    feature.append(perimeter(image))\n",
    "    feature = np.array(feature)\n",
    "    return feature / np.max(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def get_start_(image):\n",
    "    black_pixels = np.argwhere(image == 0)\n",
    "    max_x = max(black_pixels[:,0])\n",
    "    pixels_with_max_x = black_pixels[np.where(black_pixels[:,0] == max_x), :][0]\n",
    "    min_y = min(pixels_with_max_x[:,1])\n",
    "    return np.ravel(pixels_with_max_x[np.where(pixels_with_max_x[:,1] == min_y), :][0])\n",
    "\n",
    "def get_start(image):\n",
    "    black_pixels = np.argwhere(image == 0)\n",
    "    min_y = min(black_pixels[:,1])\n",
    "    pixels_with_min_y = black_pixels[np.where(black_pixels[:,1] == min_y), :][0]\n",
    "    max_x = max(pixels_with_min_y[:,0])\n",
    "    return np.ravel(pixels_with_min_y[np.where(pixels_with_min_y[:,0] == max_x), :][0])\n",
    "\n",
    "\n",
    "def get_segments(image, kernel_size = 15):\n",
    "    img = image.copy()[:,:,0]\n",
    "    n, m = img.shape\n",
    "    ret, thresh = cv2.threshold(img, 127, 255, 0)\n",
    "    img = cv2.bitwise_not(thresh)     \n",
    "    _, markers = cv2.connectedComponents(img)\n",
    "    component_count = np.amax(markers)\n",
    "    segments = []    \n",
    "    for comp in range(1, component_count + 1):\n",
    "        mask = markers == comp\n",
    "        component = img * mask\n",
    "        if np.sum(component) / 255 < 100:\n",
    "            continue\n",
    "        component = cv2.bitwise_not(component)\n",
    "        start = get_start(component)     \n",
    "        start_points = [start]\n",
    "        used_cells = []\n",
    "        segments_points = []\n",
    "        component_3 = np.stack((component,)*3, axis=-1)\n",
    "        while len(start_points) > 0:\n",
    "            start = start_points.pop(0)\n",
    "            if (0 < start[0] - kernel_size < n):\n",
    "                top_left = (start[1], start[0] - kernel_size)\n",
    "            elif start[0] - kernel_size >= n:\n",
    "                top_left = (start[1], n)\n",
    "            elif start[0] - kernel_size <= 0:\n",
    "                top_left = (start[1], 0)\n",
    "                \n",
    "            if (0 < start[1] + kernel_size < m):\n",
    "                bottom_right = (start[1] + kernel_size, start[0])\n",
    "            elif start[1] + kernel_size >= m:\n",
    "                bottom_right = (m, start[0])\n",
    "            elif start[1] + kernel_size <= 0:\n",
    "                bottom_right = (0, start[0])\n",
    "\n",
    "                \n",
    "            if top_left is None or bottom_right is None:\n",
    "                continue\n",
    "\n",
    "            segments_points.append([top_left, bottom_right])\n",
    "            top = max(0, start[0] - kernel_size)\n",
    "            bottom = min(n, start[0])\n",
    "            left = max(0, start[1])\n",
    "            right = min(m, start[1] + kernel_size)\n",
    "\n",
    "            segment = component[top:bottom, left:right]\n",
    "            s_n, s_m = segment.shape\n",
    "            if s_n < kernel_size:\n",
    "                segment = cv2.copyMakeBorder(segment,kernel_size - s_n,0,0,0,cv2.BORDER_CONSTANT,value=255)\n",
    "            if s_m < kernel_size:\n",
    "                segment = cv2.copyMakeBorder(segment,0,0,0,kernel_size - s_m,cv2.BORDER_CONSTANT,value=255)\n",
    "\n",
    "            segments_cells = list(itertools.product(range(top, bottom + 1), range(left, right + 1)))\n",
    "            if not set(segments_cells).issubset(set(used_cells)): \n",
    "                used_cells += segments_cells\n",
    "                segments.append(segment)\n",
    "            else: \n",
    "                continue\n",
    "\n",
    "            offset = 0\n",
    "            if (0 <= start[0] - kernel_size - 1 <= n) and (0 <= start[1] + kernel_size <= m):\n",
    "                top_line = component[top - 1,  left:right]   \n",
    "                if 0 in top_line:\n",
    "                    new_start = (start[0] - kernel_size - 1, start[1] + offset)\n",
    "                    if new_start not in used_cells and new_start not in start_points:\n",
    "                        start_points.append(new_start)\n",
    "\n",
    "            if (0 <= start[0] +  kernel_size + 1 <= n) and (0 <= start[1] + kernel_size <= m):\n",
    "                if bottom + 1 != n:\n",
    "                    bot_line = component[bottom + 1,  left:right]\n",
    "                    if 0 in bot_line:\n",
    "                        new_start = (start[0] + kernel_size + 1, start[1] + offset)\n",
    "                        if new_start not in used_cells and new_start not in start_points:\n",
    "                            start_points.append(new_start)\n",
    "\n",
    "            if (0 <= start[0] - kernel_size <= n) and (0 <= start[1] - kernel_size - 1 <= m):\n",
    "                left_line = component[top: bottom,  left - 1] \n",
    "                if 0 in left_line:\n",
    "                    new_start = (start[0] - offset, start[1] - kernel_size - 1)\n",
    "                    if new_start not in used_cells and new_start not in start_points:\n",
    "                        start_points.append(new_start)\n",
    "\n",
    "            if (0 <= start[0] - kernel_size <= n) and (0 <= start[1] + kernel_size + 1 <= m):\n",
    "                if right + 1 != m:   \n",
    "                    right_line = component[top: bottom,  right + 1]\n",
    "                    if 0 in right_line:\n",
    "                        new_start = (start[0] - offset, start[1] + kernel_size + 1)\n",
    "                        if new_start not in used_cells and new_start not in start_points:\n",
    "                            start_points.append(new_start)\n",
    "\n",
    "    return segments\n",
    "    \n",
    "    \n",
    "def save_segments(path, segments, count = 0):\n",
    "    for segment in segments:\n",
    "        if np.sum(segment == 0) > 10:\n",
    "            cv2.imwrite(os.path.join(path , 'segment_' + str(count) + '.png'), segment)\n",
    "            count += 1\n",
    "           \n",
    "\n",
    "def get_starts(vect):\n",
    "    inds = []\n",
    "    for i, val in enumerate(vect):\n",
    "        if val == 0 and i == 0:\n",
    "            inds.append(i)\n",
    "        if i > 0 and vect[i - 1] == 255 and val == 0:\n",
    "            inds.append(i)\n",
    "    return inds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_str2numb_numb2dict(vect):\n",
    "    str_to_ind_dict = {}\n",
    "    count = 0\n",
    "    for v in vect:\n",
    "        if v not in str_to_ind_dict.keys():\n",
    "            str_to_ind_dict[v] = count\n",
    "            count += 1\n",
    "    reverse_dict = {v:k for k, v in str_to_ind_dict.items()}\n",
    "    return str_to_ind_dict, reverse_dict\n",
    "\n",
    "def apply_dict(dict_keys, X):\n",
    "    res = []\n",
    "    for x in X:\n",
    "        res.append(dict_keys[x])\n",
    "    return res\n",
    "\n",
    "def arithmetic_round(x):\n",
    "    a = int(x)\n",
    "    b = x - a\n",
    "    if (b < 0.5): \n",
    "        return round(x)\n",
    "    else:\n",
    "        return round(x + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_knn(X, y, test_features, test_y, ind_to_str_dict, metric='chebyshev'):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=2, metric=metric)\n",
    "    neigh.fit(X, y) \n",
    "    res = neigh.predict(test_features) \n",
    "    predict = apply_dict(ind_to_str_dict, res)\n",
    "    count = 0\n",
    "    for i,j in zip(predict, test_y):\n",
    "        if i == j:\n",
    "            count += 1\n",
    "\n",
    "    print(\"top-1 autor accuracy: {}%\".format(arithmetic_round(100 * count / len(test_y))))\n",
    "\n",
    "    predict = neigh.predict_proba(test_features)\n",
    "    count = 0\n",
    "    for i, res in enumerate(predict):\n",
    "        ind = np.argpartition(res, -4)[-4:]\n",
    "        ind = apply_dict(ind_to_str_dict , ind)\n",
    "        if test_y[i] in ind:\n",
    "            count += 1\n",
    "\n",
    "    print(\"top-5 autor accuracy: {}%\".format(arithmetic_round(100 * count / len(test_y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
