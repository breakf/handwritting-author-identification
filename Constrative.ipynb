{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0, '../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import  sample\n",
    "from sklearn.utils import shuffle\n",
    "from itertools import combinations\n",
    "\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "\n",
    "     \n",
    "class WordsSequence(Sequence):\n",
    "    def __init__(self, img_dir, input_shape, batch_size, x_set, y_set=None):\n",
    "        if y_set is not None:\n",
    "            self.x, self.y = x_set, y_set\n",
    "            self.x, self.y = shuffle(self.x, self.y)\n",
    "            self.dataset = pd.DataFrame(data={'x': self.x, 'y': self.y, 'used': np.zeros_like(self.y)})\n",
    "        else:\n",
    "            self.x, self.y = x_set, None\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            return np.array([self.preprocess(fetch(self.img_dir, name)) for name in batch_x])\n",
    "        \n",
    "        unused = self.dataset.loc[self.dataset['used'] == 0]\n",
    "        if len(unused) >= self.batch_size:\n",
    "            batch_indices = unused.sample(n=self.batch_size).index\n",
    "        else:\n",
    "            batch_indices = unused.sample(n=self.batch_size, replace=True).index\n",
    "\n",
    "        self.dataset.loc[batch_indices, 'used'] = 1\n",
    "        batch_x = self.dataset.iloc[batch_indices]['x'].values\n",
    "        batch_y = self.dataset.iloc[batch_indices]['y'].values     \n",
    "        \n",
    "        pairs, labels = self.AllPositivePairSelector(batch_x, batch_y)\n",
    "      \n",
    "        anchor_images = pairs[:,0]\n",
    "        positiv_images = pairs[:,1]\n",
    "        return [np.array([self.preprocess(fetch(self.img_dir, img)) for img in anchor_images]), \n",
    "            np.array([self.preprocess(fetch(self.img_dir, img)) for img in positiv_images]), labels], []\n",
    "\n",
    "    def preprocess(self, img):\n",
    "        assert len(img.shape) == 3\n",
    "\n",
    "        h, w, _ = img.shape\n",
    "        if h / w <= self.input_shape[0] / self.input_shape[1]:\n",
    "            img = resize(img, (self.input_shape[1], int(self.input_shape[1] * h / w)))\n",
    "        else:\n",
    "            img = resize(img, (int(self.input_shape[0] * w / h), self.input_shape[0]))\n",
    "\n",
    "        img = pad(img, (self.input_shape[1], self.input_shape[0]))\n",
    "        return img / 255.  # pixel normalization\n",
    "    \n",
    "    def AllPositivePairSelector(self, x, y):\n",
    "        all_ind_pairs = np.array(list(combinations(range(len(y)), 2)))\n",
    "\n",
    "        positive_inds = all_ind_pairs[y[all_ind_pairs[:,0]] == y[all_ind_pairs[:,1]]]\n",
    "        \n",
    "        negative_inds = all_ind_pairs[y[all_ind_pairs[:,0]] != y[all_ind_pairs[:,1]]]\n",
    "       \n",
    "        positive_pairs = x[positive_inds]\n",
    "        positive_labels = [1 for _ in range(len(positive_pairs))]\n",
    "        \n",
    "        negative_pairs = x[negative_inds]\n",
    "        if len(positive_pairs) == 0:\n",
    "            pair = negative_pairs[0]\n",
    "            return np.array([pair]), np.array([0])\n",
    "            \n",
    "        shuffle_inds = sample([i for i in range(len(negative_pairs))], len(positive_pairs))\n",
    "        negative_pairs = negative_pairs[shuffle_inds]\n",
    "        negative_labels = [0 for _ in range(len(negative_pairs))]\n",
    "        \n",
    "        lables = positive_labels + negative_labels\n",
    "        pairs = np.concatenate((positive_pairs, negative_pairs), axis = 0)\n",
    "        \n",
    "        return pairs, np.array(lables)\n",
    "        \n",
    "    def on_epoch_end(self):        \n",
    "        if self.y is not None:\n",
    "            self.dataset = pd.DataFrame(data={'x': self.x, 'y': self.y, 'used': np.zeros_like(self.y)})\n",
    "            self.dataset = self.dataset.sample(n=len(self.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "def contrastive_loss_(labels, embeddings_anchor, embeddings_positive, margin=1.0):\n",
    "\n",
    "    distances = math_ops.sqrt(\n",
    "        math_ops.reduce_sum(math_ops.square(embeddings_anchor - embeddings_positive), 1))\n",
    "\n",
    "    return math_ops.reduce_mean(\n",
    "        math_ops.to_float(labels) * math_ops.square(distances) +\n",
    "        (1. - math_ops.to_float(labels)) *\n",
    "        math_ops.square(math_ops.maximum(margin - distances, 0.)),\n",
    "        name='contrastive_loss')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "def fetch(img_dir, name):\n",
    "    #print('image ' + str(name))\n",
    "    img = cv2.imread(join(img_dir, name))\n",
    "    if img.shape == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    elif img.shape == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "\n",
    "def resize(img, size=(1024, 768)):\n",
    "    assert len(size) == 2\n",
    "    return cv2.resize(img, size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def pad(img, size=(1024, 768)):\n",
    "    assert len(img.shape) == 3\n",
    "    assert len(size) == 2\n",
    "    h, w, _ = img.shape\n",
    "    #assert w <= size[0] and h <= size[1]\n",
    "    pad_vert = np.ceil((size[1]-h) / 2).astype(np.uint32)\n",
    "    pad_hor = np.ceil((size[0]-w) / 2).astype(np.uint32)\n",
    "\n",
    "    padded = np.full((size[1], size[0], 3), 255).astype(np.uint8)\n",
    "    padded[pad_vert:pad_vert+h, pad_hor:pad_hor+w, :] = img.copy()\n",
    "    return padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import  sample\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "from tensorflow.python.keras.utils.generic_utils import Progbar\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def get_str2numb_numb2dict(vect):\n",
    "    str_to_ind_dict = {}\n",
    "    count = 0\n",
    "    for v in vect:\n",
    "        if v not in str_to_ind_dict.keys():\n",
    "            str_to_ind_dict[v] = count\n",
    "            count += 1\n",
    "    reverse_dict = {v:k for k, v in str_to_ind_dict.items()}\n",
    "    return str_to_ind_dict, reverse_dict\n",
    "\n",
    "def apply_dict(dict_keys, X):\n",
    "    res = []\n",
    "    for x in X:\n",
    "        res.append(dict_keys[x])\n",
    "    return res\n",
    "    \n",
    "\n",
    "@tf.function\n",
    "def contrastive_loss(y_true, embeddings_anchor, embeddings_positive, margin=1.0):\n",
    "    distances = tf.math.sqrt(\n",
    "        tf.math.reduce_sum(\n",
    "            tf.math.squared_difference(\n",
    "                embeddings_anchor, embeddings_positive),\n",
    "            1))\n",
    "\n",
    "    return tf.math.reduce_mean(\n",
    "        tf.cast(y_true, tf.dtypes.float32) * tf.math.square(distances) +\n",
    "        (1. - tf.cast(y_true, tf.dtypes.float32)) *\n",
    "        tf.math.square(tf.math.maximum(margin - distances, 0.)),\n",
    "        name='contrastive_loss')\n",
    "\n",
    "\n",
    "\n",
    "class ContrastiveLossLayer(Layer):\n",
    "    def __init__(self, margin=1.0, name=None):\n",
    "        super(ContrastiveLossLayer, self).__init__(name=name)\n",
    "        self._margin = margin\n",
    "\n",
    "    def __call__(self, y_true, embeddings_anchor, embeddings_positive):\n",
    "        return super(ContrastiveLossLayer, self).__call__([y_true, embeddings_anchor, embeddings_positive])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        loss = contrastive_loss(*inputs, margin=self._margin)\n",
    "        self.add_loss(loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class ProgbarLossLogger(Callback):\n",
    "    def __init__(self):\n",
    "        super(ProgbarLossLogger, self).__init__()\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.epochs = self.params['epochs']\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.seen = 0\n",
    "        self.target = self.params['steps']\n",
    "\n",
    "        if self.epochs > 1:\n",
    "            print('Epoch %d/%d' % (epoch + 1, self.epochs))\n",
    "        self.progbar = Progbar(target=self.target, verbose=True, stateful_metrics=['loss'])\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        if self.seen < self.target:\n",
    "            self.log_values = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        num_steps = logs.get('num_steps', 1)\n",
    "        self.seen += num_steps\n",
    "\n",
    "        for k in self.params['metrics']:\n",
    "            if k in logs:\n",
    "                self.log_values.append((k, logs[k]))\n",
    "        self.progbar.update(self.seen, self.log_values)\n",
    "        \n",
    "        \n",
    "class ContrastiveModel:\n",
    "    def __init__(self, alpha, input_shape, cache_dir, batch_size=32):\n",
    "        self.alpha = alpha\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.embeddings = None\n",
    "        self.cache_dir = cache_dir\n",
    "        if not os.path.isdir(self.cache_dir):\n",
    "            os.makedirs(self.cache_dir)\n",
    "        self.base_model = self.build_base_model()\n",
    "        self.model = self.build_model()\n",
    "        self.model.summary()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def build_base_model(self):\n",
    "        base_network = MobileNet(input_shape=self.input_shape, alpha=self.alpha, weights=None, include_top=False, pooling='avg')        \n",
    "        op = Dense(128, activation='relu')(base_network.output)\n",
    "        output = Lambda(lambda x: K.l2_normalize(x, axis=1))(op)       \n",
    "        return Model(inputs=base_network.input, outputs=output)\n",
    "        \n",
    "    def build_model(self):\n",
    "        # self.base_model.load_weights('classification_cache/checkpoint-02.h5', by_name=True)\n",
    "        input_a = Input(shape=self.input_shape, name=\"input_a\")\n",
    "        input_b = Input(shape=self.input_shape, name=\"input_b\")\n",
    "        labels = Input(shape=(1,), name=\"labels\")\n",
    "        \n",
    "        output_a = self.base_model(input_a)\n",
    "        output_b = self.base_model(input_b)\n",
    "\n",
    "        outputs = ContrastiveLossLayer()(labels, output_a, output_b)\n",
    "        model = Model([input_a, input_b, labels], outputs=outputs)\n",
    "        return model\n",
    "    \n",
    "        \n",
    "    def train(self, train_dir, train_csv, validation_dir, validation_csv, epochs, learning_rate=0.001, margin=1):\n",
    "        train = pd.read_csv(train_csv)\n",
    "        validation = pd.read_csv(validation_csv)\n",
    "        x_train, y_train = train['file_name'].as_matrix(), train['label'].as_matrix()\n",
    "        x_validation, y_validation = validation['file_name'].as_matrix(), validation['label'].as_matrix()\n",
    "        \n",
    "        str2ind_train_dict, ind2str_train_dict = get_str2numb_numb2dict(y_train)\n",
    "        y_train = np.array(apply_dict(str2ind_train_dict, y_train))\n",
    "\n",
    "        str2ind_val_dict, ind2str_val_dict = get_str2numb_numb2dict(y_validation)\n",
    "        y_validation = np.array(apply_dict(str2ind_val_dict, y_validation))\n",
    "        \n",
    "        \n",
    "        train_generator = WordsSequence(train_dir, input_shape=self.input_shape, x_set=x_train, y_set=y_train, batch_size=self.batch_size)\n",
    "        # validation_generator = WordsSequence(validation_dir, input_shape=self.input_shape, x_set=validation_pairs, y_set=validation_y, batch_size=batch_size)        \n",
    "\n",
    "        optimize = Adam(lr=0.00001)\n",
    "        self.model.summary()\n",
    "        self.model.compile(optimizer=optimize)\n",
    "        \n",
    "        self.model.fit_generator(train_generator, shuffle=True, epochs=epochs, verbose=1, \n",
    "        callbacks=[ModelCheckpoint(filepath=os.path.join(self.cache_dir, 'checkpoint-{epoch:02d}.h5'), save_weights_only=True)])\n",
    "        \n",
    "        self.model.save('final_model.h5')\n",
    "        self.save_weights('final_weights.h5')\n",
    "    \n",
    "    def save_embeddings(self, filename):\n",
    "        self.embeddings.to_pickle(filename)\n",
    "    \n",
    "    def load_embeddings(self, filename):\n",
    "        self.embeddings = pd.read_pickle(filename)\n",
    "        \n",
    "    def save_weights(self, filename):\n",
    "        self.model.save_weights(filename)\n",
    "        \n",
    "    def load_weights(self, filename):\n",
    "        self.model.load_weights(filename, by_name=True) \n",
    "        \n",
    "    def make_embeddings(self, img_dir, csv, batch_size=1):\n",
    "        if self.embeddings is not None:\n",
    "            self.clf = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "            self.clf.fit(self.embeddings[0][0], self.embeddings[0][1])\n",
    "        else:\n",
    "            data = pd.read_csv(csv)\n",
    "            x, y = data['file_name'].as_matrix(), data['label'].as_matrix()\n",
    "            \n",
    "            self.str2ind_test_dict, self.ind2str_test_dict = get_str2numb_numb2dict(y)\n",
    "            y = np.array(apply_dict(self.str2ind_test_dict, y))\n",
    "\n",
    "            words = WordsSequence(img_dir, input_shape=self.input_shape, x_set=x, batch_size=batch_size)\n",
    "            pred = self.base_model.predict_generator(words, verbose=1)\n",
    "\n",
    "            self.clf = KNeighborsClassifier(n_neighbors=20, metric='euclidean')\n",
    "            self.clf.fit(pred, y) \n",
    "     \n",
    "            # self.embeddings =  pd.DataFrame(data=[pred, y])\n",
    "            # self.save_embeddings('embeddings_contrastive.pkl')\n",
    "    \n",
    "    def predict(self, img_dir, test_csv, batch_size=1):\n",
    "        test = pd.read_csv(test_csv)\n",
    "        x_test, y_test = test['file_name'].as_matrix(), test['label'].as_matrix()\n",
    "        \n",
    "        str2ind_test_dict, ind2str_test_dict = get_str2numb_numb2dict(y_test)\n",
    "        # test_y = np.array(apply_dict(str2ind_test_dict, y_test))\n",
    "\n",
    "        words = WordsSequence(img_dir, input_shape=self.input_shape, x_set=x_test, batch_size=batch_size)\n",
    "        test_embeddings = self.base_model.predict_generator(words, verbose=1)\n",
    "\n",
    "        res = self.clf.predict(test_embeddings) \n",
    "     \n",
    "        predict = np.array(apply_dict(ind2str_test_dict, res))\n",
    "        count = 0\n",
    "        for i,j in zip(predict, y_test):\n",
    "            if i == j:\n",
    "                count += 1\n",
    "\n",
    "        print('word accuracy: ', count / len(y_test))\n",
    "        \n",
    "        count = 0\n",
    "        autors = np.unique(y_test)\n",
    "        autor_ind = [np.argwhere(y_test == a) for a in autors]\n",
    "        \n",
    "        for i,inds in enumerate(autor_ind):\n",
    "            p = Counter(np.ravel(predict[inds])).most_common(1)[0][0]\n",
    "            if p == autors[i]:\n",
    "                count += 1\n",
    "\n",
    "        print('accuracy: ', count / len(autors))\n",
    "        \n",
    "        count = 0\n",
    "        for i,inds in enumerate(autor_ind):\n",
    "            p = [pair[0] for pair in Counter(np.ravel(predict[inds])).most_common(5)]\n",
    "            if autors[i] in p:\n",
    "                count += 1\n",
    "\n",
    "        print('top-5 autor accuracy: ', count / len(autors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dir = 'C:/Users/Anastasia/Pictures/words_train'\n",
    "validation_dir = 'C:/Users/Anastasia/Pictures/words_validation'\n",
    "test_dir = '../data/words_test'\n",
    "\n",
    "# Train\n",
    "# model = ContrastiveModel(alpha=1, input_shape=(160, 160, 3), cache_dir=\"contrastive_cache\")\n",
    "# model.train(train_dir, \"../train.csv\", validation_dir, \"../validation.csv\", epochs=500)\n",
    "\n",
    "# Predict\n",
    "# model = ContrastiveModel(alpha=1, input_shape=(160, 160, 3), cache_dir=\"contrastive_cache\")\n",
    "# model.load_weights(\"final_weigths_alpha_1/final.h5\")\n",
    "# model.load_embeddings('../data/embeddings_contrastive_1.pkl')\n",
    "# model.make_embeddings(train_dir, \"train.csv\", batch_size=1)\n",
    "# model.predict(test_dir, \"../data/test.csv\", batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = 'Literature data/constrative_cache'\n",
    "train_dir = 'Literature data/train_set'\n",
    "test_dir = 'Literature data/test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_a (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_b (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "labels (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 128)          3360064     input_a[0][0]                    \n",
      "                                                                 input_b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "contrastive_loss_layer_2 (Contr ()                   0           labels[0][0]                     \n",
      "                                                                 model_4[1][0]                    \n",
      "                                                                 model_4[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,360,064\n",
      "Trainable params: 3,338,176\n",
      "Non-trainable params: 21,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ContrastiveModel(alpha=1, input_shape=(160, 160, 3), cache_dir=cache_dir)\n",
    "# model.train(train_dir, \"../train.csv\", validation_dir, \"../validation.csv\", epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_a (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_b (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "labels (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 128)          3360064     input_a[0][0]                    \n",
      "                                                                 input_b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "contrastive_loss_layer_2 (Contr ()                   0           labels[0][0]                     \n",
      "                                                                 model_4[1][0]                    \n",
      "                                                                 model_4[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,360,064\n",
      "Trainable params: 3,338,176\n",
      "Non-trainable params: 21,888\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Output contrastive_loss_layer_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to contrastive_loss_layer_2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "self = model\n",
    "train_csv = 'Literature data/train.csv'\n",
    "test_csv = 'Literature data/test.csv'\n",
    "train = pd.read_csv(train_csv)\n",
    "#validation = pd.read_csv(validation_csv)\n",
    "x_train, y_train = train['file_name'].as_matrix(), train['label'].as_matrix()\n",
    "#x_validation, y_validation = validation['file_name'].as_matrix(), validation['label'].as_matrix()\n",
    "\n",
    "str2ind_train_dict, ind2str_train_dict = get_str2numb_numb2dict(y_train)\n",
    "y_train = np.array(apply_dict(str2ind_train_dict, y_train))\n",
    "\n",
    "#str2ind_val_dict, ind2str_val_dict = get_str2numb_numb2dict(y_validation)\n",
    "#y_validation = np.array(apply_dict(str2ind_val_dict, y_validation))\n",
    "\n",
    "\n",
    "train_generator = WordsSequence(train_dir, input_shape=self.input_shape, x_set=x_train, y_set=y_train, batch_size=self.batch_size)\n",
    "# validation_generator = WordsSequence(validation_dir, input_shape=self.input_shape, x_set=validation_pairs, y_set=validation_y, batch_size=batch_size)        \n",
    "\n",
    "optimize = Adam(lr=0.00001)\n",
    "self.model.summary()\n",
    "self.model.compile(optimizer=optimize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__call__() missing 2 required positional arguments: 'embeddings_anchor' and 'embeddings_positive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-412d0774939b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m self.model.fit_generator(train_generator, shuffle=True, epochs=500, verbose=1, \n\u001b[1;32m----> 2\u001b[1;33m         callbacks=[ModelCheckpoint(filepath=os.path.join(self.cache_dir, 'checkpoint-{epoch:02d}.h5'), save_weights_only=True)])\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[0;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m               training=training))\n\u001b[0m\u001b[0;32m    253\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __call__() missing 2 required positional arguments: 'embeddings_anchor' and 'embeddings_positive'"
     ]
    }
   ],
   "source": [
    "self.model.fit_generator(train_generator, shuffle=True, epochs=500, verbose=1, \n",
    "        callbacks=[ModelCheckpoint(filepath=os.path.join(self.cache_dir, 'checkpoint-{epoch:02d}.h5'), save_weights_only=True)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
