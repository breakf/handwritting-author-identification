{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Literature Data/train_set_3_0'\n",
    "words_path = train_path\n",
    "csv_name = 'Literature Data/train_3_0.csv'\n",
    "names = []\n",
    "authors = []\n",
    "for word_file in os.listdir(words_path):\n",
    "    label =  word_file[:word_file.find('word' )-1]\n",
    "    names.append(word_file)\n",
    "    authors.append(label)\n",
    "pd.DataFrame({\"file_name\": names, \"label\": authors}) \\\n",
    "        .to_csv(csv_name, index=False, header=True, columns = [\"file_name\", \"label\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Literature Data/test_set_3_0'\n",
    "words_path = train_path\n",
    "csv_name = 'Literature Data/test_3_0.csv'\n",
    "names = []\n",
    "authors = []\n",
    "for word_file in os.listdir(words_path):\n",
    "    label =  word_file[:word_file.find('word' )-1]\n",
    "    names.append(word_file)\n",
    "    authors.append(label)\n",
    "pd.DataFrame({\"file_name\": names, \"label\": authors}) \\\n",
    "        .to_csv(csv_name, index=False, header=True, columns = [\"file_name\", \"label\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "def fetch(img_dir, name):\n",
    "    img = cv2.imread(join(img_dir, name))\n",
    "    if img.shape == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    elif img.shape == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "\n",
    "def resize(img, size=(1024, 768)):\n",
    "    assert len(size) == 2\n",
    "    return cv2.resize(img, size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def pad(img, size=(1024, 768)):\n",
    "    assert len(img.shape) == 3\n",
    "    assert len(size) == 2\n",
    "    h, w, _ = img.shape\n",
    "    #assert w <= size[0] and h <= size[1]\n",
    "    pad_vert = np.ceil((size[1]-h) / 2).astype(np.uint32)\n",
    "    pad_hor = np.ceil((size[0]-w) / 2).astype(np.uint32)\n",
    "\n",
    "    padded = np.full((size[1], size[0], 3), 255).astype(np.uint8)\n",
    "    padded[pad_vert:pad_vert+h, pad_hor:pad_hor+w, :] = img.copy()\n",
    "    return padded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.insert(0, '../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import Sequence\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "    \n",
    "class WordsSequence(Sequence):\n",
    "    def __init__(self, img_dir, input_shape, x_set, y_set=None, batch_size=1, classification=False):\n",
    "        if classification:\n",
    "            if y_set is not None:\n",
    "                self.x, self.y = x_set, y_set\n",
    "                self.dataset = pd.DataFrame(data={'x': self.x, 'y': self.y, 'used': np.zeros_like(self.y)})\n",
    "            else:\n",
    "                self.x, self.y = x_set, None\n",
    "        else:\n",
    "            if y_set is not None:\n",
    "                self.x, self.y = x_set, y_set\n",
    "                self.x, self.y = shuffle(self.x, self.y)\n",
    "            else:\n",
    "                self.x, self.y = x_set, None\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.classification = classification\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.classification:\n",
    "            if self.y is None:\n",
    "                batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "                return np.array([self.preprocess(fetch(self.img_dir, name)) for name in batch_x])\n",
    "\n",
    "            unused = self.dataset.loc[self.dataset['used'] == 0]\n",
    "            if len(unused) >= self.batch_size:\n",
    "                batch_indices = unused.sample(n=self.batch_size).index\n",
    "            else:\n",
    "                batch_indices = unused.sample(n=self.batch_size, replace=True).index\n",
    "\n",
    "            self.dataset.loc[batch_indices, 'used'] = 1\n",
    "            batch_x = self.dataset.iloc[batch_indices]['x'].values\n",
    "            batch_y = self.dataset.iloc[batch_indices]['y'].values \n",
    "            ##########################\n",
    "            # Здесь вместо 108 - количество классов\n",
    "            return np.array([self.preprocess(fetch(self.img_dir, name)) for name in batch_x]), to_categorical(batch_y, 94)\n",
    "\n",
    "        if self.y is None:\n",
    "            x = self.x[idx]\n",
    "            return np.expand_dims(self.preprocess(fetch(self.img_dir, x)), axis=0)\n",
    "\n",
    "\n",
    "        curr_x = self.x[idx]\n",
    "        curr_y = self.y[idx]\n",
    "\n",
    "        x_1_images = self.preprocess(fetch(self.img_dir, curr_x[0]))\n",
    "        x_2_images = self.preprocess(fetch(self.img_dir, curr_x[1]))\n",
    "        return [np.expand_dims(x_1_images, axis=0), np.expand_dims(x_2_images, axis=0)], np.array([curr_y])\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "    def preprocess(self, img):\n",
    "        assert len(img.shape) == 3\n",
    "\n",
    "        h, w, _ = img.shape\n",
    "        if h / w <= self.input_shape[0] / self.input_shape[1]:\n",
    "            img = resize(img, (self.input_shape[1], int(self.input_shape[1] * h / w)))\n",
    "        else:\n",
    "            img = resize(img, (int(self.input_shape[0] * w / h), self.input_shape[0]))\n",
    "\n",
    "        img = pad(img, (self.input_shape[1], self.input_shape[0]))\n",
    "        return img / 255. \n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if (not self.classification) and (self.y is not None):\n",
    "            self.x, self.y = shuffle(self.x, self.y)\n",
    "        \n",
    "        if self.classification and self.y is not None:\n",
    "            self.dataset = pd.DataFrame(data={'x': self.x, 'y': self.y, 'used': np.zeros_like(self.y)})\n",
    "            self.dataset = self.dataset.sample(n=len(self.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import Input, Dense, Lambda, Dropout, Activation\n",
    "from keras.optimizers import rmsprop, Adam, SGD, Adagrad\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def get_str2numb_numb2dict(vect):\n",
    "    str_to_ind_dict = {}\n",
    "    count = 0\n",
    "    for v in vect:\n",
    "        if v not in str_to_ind_dict.keys():\n",
    "            str_to_ind_dict[v] = count\n",
    "            count += 1\n",
    "    reverse_dict = {v:k for k, v in str_to_ind_dict.items()}\n",
    "    return str_to_ind_dict, reverse_dict\n",
    "\n",
    "    \n",
    "def apply_dict(dict_keys, X):\n",
    "    res = []\n",
    "    for x in X:\n",
    "        if x in dict_keys.keys():\n",
    "            res.append(dict_keys[x])\n",
    "        else:\n",
    "            res.append(-1)\n",
    "    return res\n",
    "    \n",
    "    \n",
    "class Classification_model:\n",
    "    def __init__(self, alpha, input_shape, num_classes, cache_dir, train_head, batch_size=32):\n",
    "        self.alpha = alpha\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.cache_dir = cache_dir\n",
    "        self.batch_size = batch_size\n",
    "        if not os.path.isdir(self.cache_dir):\n",
    "            os.makedirs(self.cache_dir)\n",
    "        self.build_model(train_head)\n",
    "    \n",
    "    def build_model(self, train_head):        \n",
    "        # If imagenet weights are being loaded, alpha can be one of`0.25`, `0.50`, `0.75` or `1.0` only.\n",
    "        base_model = MobileNet(input_shape=self.input_shape, alpha=self.alpha, weights='imagenet', \n",
    "                               include_top=False, pooling='avg') \n",
    "        \n",
    "        # Use to pretrain head\n",
    "        # if train_head:\n",
    "            # for layer in base_model.layers[:-4]:\n",
    "                # layer.trainable = False\n",
    "            \n",
    "        # base_model.summary()\n",
    "        op = Dense(128, activation='relu')(base_model.output)\n",
    "        op = Dropout(0.00001)(op)\n",
    "        output_tensor = Dense(self.num_classes, activation='softmax')(op)\n",
    "       \n",
    "        self.model = Model(inputs=base_model.input, outputs=output_tensor)\n",
    "        self.model.summary()\n",
    "        \n",
    "    def train(self, train_dir, train_csv, epochs, learning_rate=0.00001):\n",
    "        train = pd.read_csv(train_csv)\n",
    "        train_x, train_y = train['file_name'].as_matrix(), train['label'].as_matrix()\n",
    "        \n",
    "        self.str2ind_dict, self.ind2str_dict = get_str2numb_numb2dict(train_y)\n",
    "        train_y = np.array(apply_dict(self.str2ind_dict, train_y))\n",
    "\n",
    "        train_generator = WordsSequence(img_dir=train_dir,\n",
    "                                        input_shape = self.input_shape,\n",
    "                                        x_set=train_x,\n",
    "                                        y_set=train_y,\n",
    "                                        batch_size=self.batch_size,\n",
    "                                        classification=True)\n",
    "                                        \n",
    "        optimize = rmsprop(lr=learning_rate, decay=1e-6)\n",
    "        # optimize = Adam(lr=0.00000001) \n",
    "        # optimize = SGD()\n",
    "        # optimize = Adagrad(lr=0.0001)\n",
    "        \n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=optimize, metrics=['categorical_accuracy'])\n",
    "        \n",
    "        self.model.fit_generator(train_generator,\n",
    "                                 steps_per_epoch=len(train_x)//self.batch_size,\n",
    "                                 shuffle=True,\n",
    "                                 epochs=epochs,\n",
    "                                 verbose=1, \n",
    "                                 callbacks=[ModelCheckpoint(filepath=file_path_to_checkpoint, save_weights_only=True)])\n",
    "        path_to_save_model = self.cache_dir + '/' + 'final_model.h5'\n",
    "        path_to_save_weights = self.cache_dir + '/' + 'final_weights.h5'\n",
    "        \n",
    "    def save_weights(self, filename):\n",
    "        self.model.save_weights(filename)\n",
    "        \n",
    "    def load_weights(self, filename):\n",
    "        self.model.load_weights(filename, by_name=True, skip_mismatch=True)\n",
    "        \n",
    "    def predict(self, test_dir, test_csv): \n",
    "\n",
    "        test = pd.read_csv(test_csv)\n",
    "        test_x, test_y = test['file_name'].as_matrix(), test['label'].as_matrix()\n",
    "        self.str2ind_dict, self.ind2str_dict = get_str2numb_numb2dict(test_y)\n",
    "        test_generator = WordsSequence(img_dir=test_dir,\n",
    "                                        input_shape = self.input_shape,\n",
    "                                        x_set=test_x,\n",
    "                                        batch_size=self.batch_size,\n",
    "                                        classification=True)\n",
    "                                        \n",
    "        pred = np.argmax(self.model.predict_generator(test_generator, verbose=1), axis=1)  \n",
    "        res = np.array(apply_dict(self.ind2str_dict, pred))\n",
    "        \n",
    "        count = 0\n",
    "        for i,j in zip(res, test_y):\n",
    "            if i == j:\n",
    "                count += 1\n",
    "        print('word accuracy: ', count / len(test_y))\n",
    "        \n",
    "        count = 0\n",
    "        autors = np.unique(test_y)\n",
    "        autor_ind = [np.argwhere(test_y == a) for a in autors]\n",
    "        for i,inds in enumerate(autor_ind):\n",
    "            p = Counter(np.ravel(res[inds])).most_common(1)[0][0]\n",
    "            if p == autors[i]:\n",
    "                count += 1\n",
    "\n",
    "        print('top-1 autor accuracy: ', count / len(autors))\n",
    "        \n",
    "        сount = 0\n",
    "        for i,inds in enumerate(autor_ind):\n",
    "            p = [pair[0] for pair in Counter(np.ravel(res[inds])).most_common(5)]\n",
    "            if autors[i] in p:\n",
    "                сount += 1\n",
    "\n",
    "        print('top-5 autor accuracy: ', сount / len(autors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "size=(1024, 768)\n",
    "count = 0\n",
    "test_dir = 'Literature data/test_set_3_0'\n",
    "imgs = os.listdir(test_dir)\n",
    "for j, img_p in enumerate(imgs):\n",
    "    path = test_dir + '/' + img_p\n",
    "    img = cv2.imread(path)\n",
    "    assert len(img.shape) == 3\n",
    "    assert len(size) == 2\n",
    "    h, w, _ = img.shape\n",
    "    if w > size[0] or h > size[1]:\n",
    "        os.remove(path)\n",
    "        count += 1\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "size=(1024, 768)\n",
    "count = 0\n",
    "test_dir = 'Literature data/train_set_3_0'\n",
    "imgs = os.listdir(test_dir)\n",
    "for j, img_p in enumerate(imgs):\n",
    "    path = test_dir + '/' + img_p\n",
    "    img = cv2.imread(path)\n",
    "    assert len(img.shape) == 3\n",
    "    assert len(size) == 2\n",
    "    h, w, _ = img.shape\n",
    "    if w > size[0] or h > size[1]:\n",
    "        os.remove(path)\n",
    "        count += 1\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 160, 160, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 161, 161, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 80, 80, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 80, 80, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 80, 80, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 80, 80, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 80, 80, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 80, 80, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 80, 80, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 80, 80, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 80, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 81, 81, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 40, 40, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 40, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 40, 40, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 40, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 40, 40, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 40, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 40, 40, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 40, 40, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 40, 40, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 41, 41, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 20, 20, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 20, 20, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 20, 20, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 20, 20, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 20, 20, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 20, 20, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 20, 20, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 20, 20, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 21, 21, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 10, 10, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 10, 10, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 10, 10, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 10, 10, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 10, 10, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 10, 10, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 10, 10, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 10, 10, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 10, 10, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 10, 10, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 10, 10, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 10, 10, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 10, 10, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 11, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 5, 5, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 5, 5, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 5, 5, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 5, 5, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 5, 5, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 5, 5, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 5, 5, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 5, 5, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 5, 5, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 5, 5, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 5, 5, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 94)                12126     \n",
      "=================================================================\n",
      "Total params: 3,372,190\n",
      "Trainable params: 3,350,302\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cache_dir = 'Literature data/cache_3_0'\n",
    "train_dir = 'Literature data/train_set_3_0'\n",
    "test_dir = 'Literature data/test_set_3_0'\n",
    "# Train\n",
    "model = Classification_model(alpha=1, input_shape=(160,160,3), num_classes=94, cache_dir=cache_dir, train_head=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "self = model\n",
    "learning_rate=0.00001\n",
    "train_csv = 'Literature Data/train_3_0.csv'\n",
    "test_csv = 'Literature Data/test_3_0.csv'\n",
    "train = pd.read_csv(train_csv)\n",
    "train_x, train_y = train['file_name'].as_matrix(), train['label'].as_matrix()\n",
    "\n",
    "self.str2ind_dict, self.ind2str_dict = get_str2numb_numb2dict(train_y)\n",
    "train_y = np.array(apply_dict(self.str2ind_dict, train_y))\n",
    "\n",
    "train_generator = WordsSequence(img_dir=train_dir,\n",
    "                                input_shape = self.input_shape,\n",
    "                                x_set=train_x,\n",
    "                                y_set=train_y,\n",
    "                                batch_size=self.batch_size,\n",
    "                                classification=True)\n",
    "\n",
    "optimize = rmsprop(lr=learning_rate, decay=1e-6)\n",
    "# optimize = Adam(lr=0.00000001) \n",
    "# optimize = SGD()\n",
    "# optimize = Adagrad(lr=0.0001)\n",
    "\n",
    "self.model.compile(loss='categorical_crossentropy', optimizer=optimize, metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 701s 7s/step - loss: 4.7955 - categorical_accuracy: 0.0075\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 703s 7s/step - loss: 4.5018 - categorical_accuracy: 0.0272\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 708s 7s/step - loss: 4.2956 - categorical_accuracy: 0.0541\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 713s 7s/step - loss: 4.1343 - categorical_accuracy: 0.1000\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 709s 7s/step - loss: 3.9690 - categorical_accuracy: 0.1391\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 680s 7s/step - loss: 3.8145 - categorical_accuracy: 0.1641\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 680s 7s/step - loss: 3.6820 - categorical_accuracy: 0.1947\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 682s 7s/step - loss: 3.5440 - categorical_accuracy: 0.2353\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 687s 7s/step - loss: 3.4009 - categorical_accuracy: 0.2659\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 690s 7s/step - loss: 3.2795 - categorical_accuracy: 0.2931\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 691s 7s/step - loss: 3.1401 - categorical_accuracy: 0.3247\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 690s 7s/step - loss: 3.0117 - categorical_accuracy: 0.3587\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 695s 7s/step - loss: 2.8974 - categorical_accuracy: 0.3931\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 694s 7s/step - loss: 2.7982 - categorical_accuracy: 0.4184\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 694s 7s/step - loss: 2.6663 - categorical_accuracy: 0.4522\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 696s 7s/step - loss: 2.5599 - categorical_accuracy: 0.4794\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 695s 7s/step - loss: 2.4311 - categorical_accuracy: 0.5184\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 697s 7s/step - loss: 2.3106 - categorical_accuracy: 0.5550\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 685s 7s/step - loss: 2.2132 - categorical_accuracy: 0.5725\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 677s 7s/step - loss: 2.1358 - categorical_accuracy: 0.6003\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 677s 7s/step - loss: 2.0141 - categorical_accuracy: 0.6288\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 678s 7s/step - loss: 1.9119 - categorical_accuracy: 0.6466\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 680s 7s/step - loss: 1.8130 - categorical_accuracy: 0.6903\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 680s 7s/step - loss: 1.7357 - categorical_accuracy: 0.6997\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 689s 7s/step - loss: 1.6480 - categorical_accuracy: 0.7291\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 684s 7s/step - loss: 1.5607 - categorical_accuracy: 0.7522\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 685s 7s/step - loss: 1.4623 - categorical_accuracy: 0.7809\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 685s 7s/step - loss: 1.3814 - categorical_accuracy: 0.7978\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 687s 7s/step - loss: 1.3161 - categorical_accuracy: 0.8197\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 690s 7s/step - loss: 1.2313 - categorical_accuracy: 0.8403\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 681s 7s/step - loss: 1.1912 - categorical_accuracy: 0.8419\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 667s 7s/step - loss: 1.1113 - categorical_accuracy: 0.8750\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 665s 7s/step - loss: 1.0558 - categorical_accuracy: 0.8775\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 667s 7s/step - loss: 0.9785 - categorical_accuracy: 0.8947\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 669s 7s/step - loss: 0.9043 - categorical_accuracy: 0.9081\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 673s 7s/step - loss: 0.8537 - categorical_accuracy: 0.9166\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 672s 7s/step - loss: 0.8342 - categorical_accuracy: 0.9206\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 682s 7s/step - loss: 0.7628 - categorical_accuracy: 0.9287\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 673s 7s/step - loss: 0.7235 - categorical_accuracy: 0.9381\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 673s 7s/step - loss: 0.6457 - categorical_accuracy: 0.9469\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 673s 7s/step - loss: 0.6149 - categorical_accuracy: 0.9450\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 677s 7s/step - loss: 0.5746 - categorical_accuracy: 0.9575\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 678s 7s/step - loss: 0.5429 - categorical_accuracy: 0.9606\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 678s 7s/step - loss: 0.5050 - categorical_accuracy: 0.9669\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 678s 7s/step - loss: 0.4816 - categorical_accuracy: 0.9641\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 678s 7s/step - loss: 0.4466 - categorical_accuracy: 0.9694\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 695s 7s/step - loss: 0.3838 - categorical_accuracy: 0.9803\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 654s 7s/step - loss: 0.3771 - categorical_accuracy: 0.9741\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 659s 7s/step - loss: 0.3399 - categorical_accuracy: 0.9772\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 695s 7s/step - loss: 0.3278 - categorical_accuracy: 0.9750\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 704s 7s/step - loss: 0.2985 - categorical_accuracy: 0.9819\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 710s 7s/step - loss: 0.2697 - categorical_accuracy: 0.9834\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 706s 7s/step - loss: 0.2567 - categorical_accuracy: 0.9794\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 733s 7s/step - loss: 0.2316 - categorical_accuracy: 0.9844\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 743s 7s/step - loss: 0.2237 - categorical_accuracy: 0.9822\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 751s 8s/step - loss: 0.2254 - categorical_accuracy: 0.9766\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 736s 7s/step - loss: 0.2078 - categorical_accuracy: 0.9787\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 743s 7s/step - loss: 0.2018 - categorical_accuracy: 0.9819\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 726s 7s/step - loss: 0.1660 - categorical_accuracy: 0.9837\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 757s 8s/step - loss: 0.1444 - categorical_accuracy: 0.9853\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 722s 7s/step - loss: 0.1386 - categorical_accuracy: 0.9803\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 752s 8s/step - loss: 0.1399 - categorical_accuracy: 0.9862\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 732s 7s/step - loss: 0.1357 - categorical_accuracy: 0.9784\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 721s 7s/step - loss: 0.1299 - categorical_accuracy: 0.9812\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 721s 7s/step - loss: 0.1170 - categorical_accuracy: 0.9819\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 673s 7s/step - loss: 0.1081 - categorical_accuracy: 0.9831\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 647s 6s/step - loss: 0.1138 - categorical_accuracy: 0.9812\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 651s 7s/step - loss: 0.1013 - categorical_accuracy: 0.9856\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 654s 7s/step - loss: 0.0948 - categorical_accuracy: 0.9844\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 655s 7s/step - loss: 0.0864 - categorical_accuracy: 0.9853\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 668s 7s/step - loss: 0.0865 - categorical_accuracy: 0.9837\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 664s 7s/step - loss: 0.0757 - categorical_accuracy: 0.9866\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 665s 7s/step - loss: 0.0794 - categorical_accuracy: 0.9822\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 654s 7s/step - loss: 0.0685 - categorical_accuracy: 0.9856\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 647s 6s/step - loss: 0.0771 - categorical_accuracy: 0.9781\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 656s 7s/step - loss: 0.0749 - categorical_accuracy: 0.9809\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 685s 7s/step - loss: 0.0689 - categorical_accuracy: 0.9819\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 650s 7s/step - loss: 0.0711 - categorical_accuracy: 0.9812\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 646s 6s/step - loss: 0.0637 - categorical_accuracy: 0.9822\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 651s 7s/step - loss: 0.0621 - categorical_accuracy: 0.9834\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 652s 7s/step - loss: 0.0680 - categorical_accuracy: 0.9787\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 648s 6s/step - loss: 0.0685 - categorical_accuracy: 0.9744\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 648s 6s/step - loss: 0.0526 - categorical_accuracy: 0.9859\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 652s 7s/step - loss: 0.0565 - categorical_accuracy: 0.9828\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 662s 7s/step - loss: 0.0552 - categorical_accuracy: 0.9803\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 660s 7s/step - loss: 0.0504 - categorical_accuracy: 0.9828\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 761s 8s/step - loss: 0.0546 - categorical_accuracy: 0.9825\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 772s 8s/step - loss: 0.0528 - categorical_accuracy: 0.9816\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 797s 8s/step - loss: 0.0583 - categorical_accuracy: 0.9806\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 749s 7s/step - loss: 0.0457 - categorical_accuracy: 0.9828\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 684s 7s/step - loss: 0.0512 - categorical_accuracy: 0.9831\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 680s 7s/step - loss: 0.0564 - categorical_accuracy: 0.9781\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 679s 7s/step - loss: 0.0497 - categorical_accuracy: 0.9816\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 674s 7s/step - loss: 0.0450 - categorical_accuracy: 0.9844\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 669s 7s/step - loss: 0.0481 - categorical_accuracy: 0.9803\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 665s 7s/step - loss: 0.0461 - categorical_accuracy: 0.9841\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 710s 7s/step - loss: 0.0405 - categorical_accuracy: 0.9816\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 738s 7s/step - loss: 0.0402 - categorical_accuracy: 0.9806\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 699s 7s/step - loss: 0.0379 - categorical_accuracy: 0.9831\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 689s 7s/step - loss: 0.0373 - categorical_accuracy: 0.9822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1891c578470>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "file_path_to_checkpoint=self.cache_dir + '/checkpoint-{epoch:02d}.h5'\n",
    "self.model.fit_generator(train_generator,\n",
    "                                 steps_per_epoch=len(train_x)//self.batch_size,\n",
    "                                 shuffle=True,\n",
    "                                 epochs=epochs,\n",
    "                                 verbose=1, \n",
    "                                 callbacks=[ModelCheckpoint(filepath=file_path_to_checkpoint, save_weights_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = 'Literature Data/cache_3_0/my_model.h5'\n",
    "self.model.save(path_model)\n",
    "path_to_save_weights = self.cache_dir + '/' + 'final_weights.h5'\n",
    "self.save_weights(path_to_save_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(test_csv)\n",
    "test_x, test_y = test['file_name'].as_matrix(), test['label'].as_matrix()\n",
    "self.str2ind_dict, self.ind2str_dict = get_str2numb_numb2dict(test_y)\n",
    "test_generator = WordsSequence(img_dir=test_dir,\n",
    "                                input_shape = self.input_shape,\n",
    "                                x_set=test_x,\n",
    "                                batch_size=self.batch_size,\n",
    "                                classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 219s 3s/step\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(self.model.predict_generator(test_generator, verbose=1), axis=1)  \n",
    "res = np.array(apply_dict(self.ind2str_dict, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word accuracy:  0.16939019529693106\n",
      "top-1 autor accuracy:  0.30851063829787234\n",
      "top-5 autor accuracy:  0.5957446808510638\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i,j in zip(res, test_y):\n",
    "    if i == j:\n",
    "        count += 1\n",
    "print('word accuracy: ', count / len(test_y))\n",
    "\n",
    "count = 0\n",
    "autors = np.unique(test_y)\n",
    "autor_ind = [np.argwhere(test_y == a) for a in autors]\n",
    "for i,inds in enumerate(autor_ind):\n",
    "    p = Counter(np.ravel(res[inds])).most_common(1)[0][0]\n",
    "    if p == autors[i]:\n",
    "        count += 1\n",
    "\n",
    "print('top-1 autor accuracy: ', count / len(autors))\n",
    "\n",
    "сount = 0\n",
    "for i,inds in enumerate(autor_ind):\n",
    "    p = [pair[0] for pair in Counter(np.ravel(res[inds])).most_common(5)]\n",
    "    if autors[i] in p:\n",
    "        сount += 1\n",
    "\n",
    "print('top-5 autor accuracy: ', сount / len(autors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
